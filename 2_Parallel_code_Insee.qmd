---
title: "Parallel_code_Insee : Reducing the 3 GB INSEE's Database"
author: "C. BAZILE & K. SANTOS"
format: html
editor: visual
execute :
  keep-md: TRUE
  warning: FALSE
---

<center>

# Presentation of the document

</center>

The codes below describe the steps we used to reduce the size of the initial Insee 3 GB database in a smaller - and therefore more workable - database.

The INSEE database is titled : "***Données harmonisées des recensements de la population à partir de 1968***".

It was not possible to upload the data on GitHub, but it can be downloaded on the following link : <https://www.insee.fr/fr/statistiques/6671801?sommaire=2414232>

In English, it can be translated as: "***Harmonized population census data from 1968***"

It contains socio-demographic information on the French population by department between 1968 and 2019.

The format of the database makes it quite memory-consuming.

To facilitate its exploitation, we work on a solution to reduce the size of the aforementioned database. This document reconstructs the steps of our work.

<br>

# Codes

## Setup

```{r Opening_the_packages, results='hide'}
 here::i_am("CNC_INSEE_project.Rproj")

library(data.table) 

# The  "data.table" package will be  one of our key tools. Indeed, its characteristics allows us to exploit easily big database which will be usefull in our situation 

library(here)
library(dplyr)
library(tidyr)
library(readr)
```

<br>

## Importation of the data using the data.table package

To reproduce this step download the database on (the data are also include in the zip document) : <https://www.insee.fr/fr/statistiques/6671801?sommaire=2414232>

```{r Importation_of_the_data, results='hide'}

insee <- fread("Data/Ficdep19.csv")
```

<br>

## Main codes

### Explanation of the process

```{r Calculation_of_the_number_of_variable, echo=FALSE, results='hide'}
metadata <- read_delim("Data/varmod_FICDEP_2019.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE) 

nb_val <- metadata %>% 
  summarize(unique_count = n_distinct(LIB_VAR))


```

The original database is composed of `r nb_val` variables.

"POND" is our key variable. It gives us the number of inhabitant regarding the different characteristics detailed by the other variables (department, age, ...).

However, the format of the table tends to create a RAM-consuming CSV. Some characteristic variables have an important number of "categories"/"levels". For example, 5 variables have more than 100 categories. The result is that, in total, we have a significant number of potential combinations. It explains the important size of the INSEE's database.

The reality is that our project do not need so many combinations. Indeed, among these variables we find :

-   some variables which have many levels but are useless for us;

-   but also the variable AGE_REV which gives us the age that an inhabitant can have. While this variable is quite important, it has too many levels (one level for each age).

<br>

*Annex : Table on the original characteristic variable*

```{r Creating_our_annex_table, echo=FALSE}
metadata <- metadata %>% rename("Variable"=LIB_VAR)
metadata <- metadata %>% rename("Code"=COD_VAR)

table_stat <- metadata %>% 
  group_by(Variable, Code) %>% 
  summarize("Number of potential values" = n())

table_stat %>%
  filter(Code != "POND")%>%
  arrange(Code) %>%
  knitr::kable(caption = "Number of values that take each 'characteristics' variables", format="html", align = "c")

# We did not keep the variable 'Ponderation' because the statistic computed with `n()` can be misleading. 

# Indeed, in the metadata (varmod_FICDEP_2019.csv), unlike the other variables, 'POND' does not have a row for each value it can take.

```

We have two goals for reducing our database

1.  Simplify AGE_REV by replacing its 120 levels with 5 that are age ranges. The use of 5 age ranges corresponding to 15-year interval is inspired by Insee's work. The institute often used this interval as a convention when it writes its "Dossier complet", an annual report individually dedicated to each French township.

2.  Use the "group_by" function to keep the information of the values contains in the variable "POND" with the variables that are of interest to us uniquely

<br>

### Main codes in themselves

```{r Creation_of_our_new_database}
insee <- insee |> 
  mutate(AGE_GROUP = case_when( AGE_REV < 15 ~ "<15", 
                                between(AGE_REV, 15, 29) ~ "15-29", 
                                between(AGE_REV, 30, 44) ~ "30-44", 
                                between(AGE_REV, 45, 59) ~ "45-59", 
                                between(AGE_REV, 60, 74) ~ "60-74", 
                                AGE_REV > 75 ~ "75 and more")) 

Insee_cleanv3 <- insee |> 
  group_by(AN_RECENS,DEP_RES_21,AGE_GROUP,TYP_ACT,CSP) |>
  summarize( POND2 = sum(POND, na.rm = TRUE)) 

```

<br>

## Export of our result in a CSV

```{r Export_to_csv}
write.csv(Insee_cleanv3, file = "Data/INSEE_cleanv3.csv")
```
